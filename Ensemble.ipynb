{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uU0Cy3HBikWr"
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# for reading and displaying images \n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "import h5py\n",
    "\n",
    "#for random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#for CNN\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIVmU-F4ir8u"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0brTdN7keyy"
   },
   "source": [
    "### Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SveqaT0Gkcvo"
   },
   "outputs": [],
   "source": [
    " def split_samples(cost_df):\n",
    "    def padding_frames(frames, fix_length):\n",
    "        if len(frames) < fix_length:\n",
    "            frames = frames + [[[0] * 8] * 8] * (fix_length - len(frames))\n",
    "        elif len(frames) > fix_length:\n",
    "            frames = frames[:fix_length]\n",
    "        return frames\n",
    "\n",
    "    touches = []\n",
    "    gestures = []\n",
    "    # variants = []\n",
    "\n",
    "    temp_frames = []\n",
    "    for index, row in cost_df.iterrows():\n",
    "        if row['frame'] == 1:\n",
    "            gestures.append(row['gesture'])\n",
    "            # variants.append(row['variant'])\n",
    "            touches.append([padding_frames(temp_frames, 1750)])\n",
    "            temp_frames = []\n",
    "        one_frame = np.array(row.tolist()[4:]).reshape((8, 8)).tolist()\n",
    "        temp_frames.append(one_frame)\n",
    "\n",
    "    touches.append([padding_frames(temp_frames, 1750)])\n",
    "    touches = touches[1:]\n",
    "\n",
    "    return np.array(touches, dtype='int16'), np.array(gestures, dtype='int16') - 1\n",
    "\n",
    "\n",
    "def touches_3d_to_2d(touches):\n",
    "    \"\"\"(M, 1, 1750, 8, 8) -> (M, 1750, 8, 8)\"\"\"\n",
    "    touches = np.apply_along_axis(lambda x: x[0], 1, touches)\n",
    "    return touches\n",
    "\n",
    "\n",
    "def one_touch_remove_padding(touch_padding, dimension=1):\n",
    "    \"\"\"remove padding of one touch (all frames of a single gesture)\n",
    "\n",
    "    Parameters:\n",
    "    touch_padding (ndarray) -- one touch with padding values, shape (1750, 8, 8)\n",
    "    dimension (int: 1 or 2) -- dimension of frame, 1: 64; 2: 8x8\n",
    "\n",
    "    Returns:\n",
    "    lists: one touch without padding values, shape (N, 64)\n",
    "    \"\"\"\n",
    "    frames_no_padding = []\n",
    "    for frame_iter in touch_padding:\n",
    "        if np.sum(frame_iter) != 0:\n",
    "            if dimension == 1:\n",
    "                frames_no_padding.append(frame_iter.flatten().tolist())\n",
    "            else:\n",
    "                frames_no_padding.append(frame_iter.tolist())\n",
    "    return frames_no_padding\n",
    "\n",
    "\n",
    "def touches_remove_padding(touches_padding, dimension=1):\n",
    "    \"\"\"remove padding of touches (gestures)\n",
    "\n",
    "    Parameters:\n",
    "    touches_padding (ndarray) -- touches with padding values, shape (M, 1750, 8, 8) or (M, 1, 1750, 8, 8)\n",
    "    dimension (int: 1 or 2) -- dimension of frame, 1: 64; 2: 8x8\n",
    "\n",
    "    Return:\n",
    "    lists: touches without padding values, shape (M, N, 64), cannot convert to ndarray because N is not fixed.\n",
    "    \"\"\"\n",
    "    if (touches_padding.shape[1] == 1) and (len(touches_padding.shape) == 5):\n",
    "        touches_padding = touches_3d_to_2d(\n",
    "            touches_padding\n",
    "        )  # (M, 1, 1750, 8, 8) to (M, 1750, 8, 8)\n",
    "\n",
    "    touches_no_padding = []\n",
    "    for touch_padding in touches_padding:\n",
    "        touches_no_padding.append(one_touch_remove_padding(touch_padding, dimension=dimension))\n",
    "    return touches_no_padding\n",
    "\n",
    "def generate_random_string(N=8):\n",
    "  \"\"\"generate a random string as the id of a gesture record\n",
    "  Parameters:\n",
    "  N (int) default 8 -- the character number of string generated\n",
    "\n",
    "  Return:\n",
    "  String. the generated string\n",
    "  \n",
    "  \"\"\"\n",
    "  return ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(N))\n",
    "\n",
    "\n",
    "def padding_sample_3dcnn(touches_list, gestures_list, max_frame=100):\n",
    "  \"\"\"\n",
    "  divede the example to subframe(suitable for 3d cnn)\n",
    "\n",
    "  Parameters:\n",
    "  touches_list (list): the list contains each gesture's all frames\n",
    "  gestures_list (list): the list contains each gesture's label\n",
    "  max_frame (int): the frame length used to divide sample\n",
    "\n",
    "  Return:\n",
    "  touches (ndarray): size (number_of_sample, 1, max_frame, 8, 8 )\n",
    "  gestures (ndarray): size (number_of_sample,)\n",
    "  gestures_identity (ndarray): size (number_of_sample), contains the id of each gesture, needed when accuracy test\n",
    "\n",
    "  \"\"\"\n",
    "  def padding_frames(frames, fix_length):\n",
    "        if len(frames) < fix_length:\n",
    "            frames = frames + [[[0] * 8] * 8] * (fix_length - len(frames))\n",
    "        return frames\n",
    "  touches = []\n",
    "  gestures = []\n",
    "  gestures_identity = []\n",
    "\n",
    "  for touch,gesture in zip(touches_list,gestures_list):\n",
    "    \n",
    "    gesture_id = generate_random_string()\n",
    "    count = len(touch)//max_frame\n",
    "    if count >0:\n",
    "      for i in range(count):\n",
    "        touches.append([touch[0+i*max_frame:max_frame+i*max_frame]])\n",
    "        gestures.append(gesture)\n",
    "        gestures_identity.append(gesture_id)\n",
    "    touches.append([padding_frames(touch[0+count*max_frame:],max_frame)])\n",
    "    gestures.append(gesture)\n",
    "    gestures_identity.append(gesture_id)\n",
    "    \n",
    "  return np.array(touches, dtype='int16'), np.array(gestures, dtype='int16'), np.array(gestures_identity)\n",
    "\n",
    "\n",
    "def padding_sample_2dcnn(touches_list, gestures_list, max_frame=100):\n",
    "  \"\"\"\n",
    "  divede the example to subframe(suitable for 3d cnn)\n",
    "\n",
    "  Parameters:\n",
    "  touches_list (list): the list contains each gesture's all frames\n",
    "  gestures_list (list): the list contains each gesture's label\n",
    "  max_frame (int): the frame length used to divide sample\n",
    "\n",
    "  Return:\n",
    "  touches (ndarray): size (number_of_sample, 1, max_frame, 8, 8 )\n",
    "  gestures (ndarray): size (number_of_sample,)\n",
    "  gestures_identity (ndarray): size (number_of_sample), contains the id of each gesture, needed when accuracy test\n",
    "\n",
    "  \"\"\"\n",
    "  def padding_frames(frames, fix_length):\n",
    "        if len(frames) < fix_length:\n",
    "            frames = frames + [[[0] * 8] * 8] * (fix_length - len(frames))\n",
    "        return frames\n",
    "  touches = []\n",
    "  gestures = []\n",
    "  gestures_identity = []\n",
    "\n",
    "  for touch,gesture in zip(touches_list,gestures_list):\n",
    "    \n",
    "    gesture_id = generate_random_string()\n",
    "    count = len(touch)//max_frame\n",
    "    if count >0:\n",
    "      for i in range(count):\n",
    "        touches.append(touch[0+i*max_frame:max_frame+i*max_frame])  #removed the braces here []\n",
    "        gestures.append(gesture)\n",
    "        gestures_identity.append(gesture_id)\n",
    "    touches.append(padding_frames(touch[0+count*max_frame:],max_frame))  #removed the braces []\n",
    "    gestures.append(gesture)\n",
    "    gestures_identity.append(gesture_id)\n",
    "    \n",
    "  return np.array(touches, dtype='int16'), np.array(gestures, dtype='int16') , np.array(gestures_identity)\n",
    "\n",
    "\n",
    "def split_samples_subframe(cost_df):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    lists: touches without padding values, shape (M, N, 8，8), cannot convert to ndarray because N is not fixed.\n",
    "    \"\"\"\n",
    "    def padding_frames(frames, fix_length):\n",
    "        if len(frames) < fix_length:\n",
    "            frames = frames + [[[0] * 8] * 8] * (fix_length - len(frames))\n",
    "        elif len(frames) > fix_length:\n",
    "            frames = frames[:fix_length]\n",
    "        return frames\n",
    "\n",
    "    touches = []\n",
    "    gestures = []\n",
    "\n",
    "    temp_frames = []\n",
    "    for index, row in cost_df.iterrows():\n",
    "        if row['frame'] == 1:\n",
    "            gestures.append(row['gesture'])\n",
    "            touches.append(temp_frames)\n",
    "            temp_frames = []\n",
    "        one_frame = np.array(row.tolist()[4:]).reshape((8, 8)).tolist()\n",
    "        temp_frames.append(one_frame)\n",
    "\n",
    "    touches.append(temp_frames)\n",
    "    touches = touches[1:]\n",
    "\n",
    "    return touches, gestures\n",
    "\n",
    "\n",
    "def MN88_to_MN64(touches_88):\n",
    "    \"\"\"\n",
    "    from shape (M, N, 8，8) to shape (M, N, 64)\n",
    "    \"\"\"\n",
    "    touches_64 = []\n",
    "    for i in range(len(touches_88)):\n",
    "        temp_sample = []\n",
    "        for j in range(len(touches_88[i])):\n",
    "            temp_frame = np.array(touches_88[i][j]).flatten().tolist()\n",
    "            temp_sample.append(temp_frame)\n",
    "        touches_64.append(temp_sample)\n",
    "    return touches_64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPuT8MxbsF9I"
   },
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eU5mUW2Qio6T",
    "outputId": "7031beb0-8409-4bee-ea1d-b4a1b2c3a750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6v8kU1YUi5tx",
    "outputId": "a6992ccb-1b76-4aec-f365-2baa331af278"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/CoST.csv\", sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afMyLf6Bi8X8",
    "outputId": "8ec000da-dfc5-4a04-c7de-bb7aaaf00bff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "touches_88, gestures = split_samples_subframe(df)\n",
    "gestures = np.array(gestures) - 1\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpdxDOoOjG7z",
    "outputId": "dd210070-22e3-445b-a2ae-9694d2746dba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(touches_88, gestures, test_size=0.2, random_state=42, stratify=gestures)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
    "\n",
    "num_classes = 14\n",
    "\n",
    "del touches_88\n",
    "del gestures\n",
    "# del variants\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGeEi1oPj9Dm"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwGT52mckOit"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDmf0TCmkOCp"
   },
   "outputs": [],
   "source": [
    "# X_train_rf, X_test_rf: lists; shape: (M, N, 64); M: number of samples; N: number of frames; cannot convert to ndarray because N is not fixed\n",
    "X_train_rf = MN88_to_MN64(X_train)\n",
    "X_test_rf = MN88_to_MN64(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqnzwGYUlOJa"
   },
   "source": [
    "### Feature Extraction-global feature \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGf8LxABLyUr"
   },
   "outputs": [],
   "source": [
    "#Feature extraction\n",
    "\n",
    "#global feature group\n",
    "def flatten_lists(list_of_lists):\n",
    "    list = [val for sublist in list_of_lists for val in sublist]\n",
    "    return list\n",
    "\n",
    "def num_of_frames(touch):\n",
    "    return len(touch)\n",
    "\n",
    "def avg_pressure_on_64_chs_over_all_frames(touch):\n",
    "    all_values = flatten_lists(touch)\n",
    "    return np.mean(all_values)\n",
    "\n",
    "def max_value_in_all(touch):\n",
    "    all_values=flatten_lists(touch)\n",
    "    return max(all_values)\n",
    "\n",
    "def no_signal_frames(touch):\n",
    "    count = 0\n",
    "    t = 50\n",
    "    for frame in touch:\n",
    "        if np.mean(frame) < t:\n",
    "            count += 1\n",
    "    return count / len(touch)\n",
    "\n",
    "#Variations around a specific value c (variations around the central value of temporal signal)\n",
    "#35th, 50th, 65th, 80th and 95th-percentile of the maximal value. \n",
    "#1.number of crossing around c\n",
    "#2.the average slope of each crossing. \n",
    "def variations_around_c(touch):\n",
    "    def num_of_crossing_and_avg_slope(array, c):\n",
    "        count = 0\n",
    "        slopes = []\n",
    "        total = len(array) - 1\n",
    "        for i in range(total):\n",
    "            if (array[i] - c) * (array[i + 1] - c) < 0:\n",
    "                count += 1\n",
    "                slopes.append((array[i + 1] - array[i]) / (array[i] + array[i + 1]))\n",
    "        return count, np.mean(slopes)\n",
    "\n",
    "    array = np.array(touch).mean(axis=0)\n",
    "    sorted_array = np.sort(array)\n",
    "    length = len(sorted_array)\n",
    "    c_35 = sorted_array[int(65 / 100 * length)]\n",
    "    c_50 = sorted_array[int(50 / 100 * length)]\n",
    "    c_65 = sorted_array[int(35 / 100 * length)]\n",
    "    c_80 = sorted_array[int(20 / 100 * length)]\n",
    "    c_95 = sorted_array[int(5 / 100 * length)]\n",
    "\n",
    "    c_list = [c_35, c_50, c_65, c_80, c_95]\n",
    "    rtn = (\n",
    "        []\n",
    "    )  # [num_of_crossing_when_c_35, avg_slope_when_c_35, num_of_crossing_when_c_50, avg_slope_when_c_50, ...]\n",
    "    for c in c_list:\n",
    "        rtn.extend(num_of_crossing_and_avg_slope(array, c))\n",
    "\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlmhVHK_Md9h",
    "outputId": "433b3a5c-ed6b-46b9-b6d7-49e11aedc48a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#X_train_rf = touches_remove_padding(X_train_rf)\n",
    "group1_feature1_data = []  # num_of_frames: value; shape: (N,)\n",
    "group1_feature2_data = []  # avg_pressure_on_64_chs_over_all_frames; shape: (N,)\n",
    "group1_feature3_data = []  # max_value_in_all,shape:(N,)\n",
    "group1_feature4_data = []  # no_signal_frames,shape:(N,)\n",
    "group1_feature5_data = []  # variations_around_c; shape: (N, 10)\n",
    "\n",
    "all_data = []\n",
    "for i in range(len(X_train_rf)):\n",
    "    group1_feature1_data.append(num_of_frames(X_train_rf[i]))\n",
    "    group1_feature2_data.append(avg_pressure_on_64_chs_over_all_frames(X_train_rf[i]))\n",
    "    group1_feature3_data.append(max_value_in_all(X_train_rf[i]))\n",
    "    group1_feature4_data.append(no_signal_frames(X_train_rf[i]))\n",
    "    group1_feature5_data.append(variations_around_c(X_train_rf[i]))\n",
    "\n",
    "    \n",
    "all_data.append(group1_feature1_data)\n",
    "all_data.append(group1_feature2_data)\n",
    "all_data.append(group1_feature3_data)\n",
    "all_data.append(group1_feature4_data)\n",
    "\n",
    "#ned_df is the feature group 1 without 5th features \n",
    "new_df = pd.DataFrame(all_data)\n",
    "new_df=new_df.T\n",
    "new_df.columns=[\"num_of_frames\", \"avg_pressure_on_64_chs_over_all_frames\",\"max_value_in_all\",\"no_signal_frames\"]\n",
    "\n",
    "feature5=pd.DataFrame(group1_feature5_data)\n",
    "feature5.columns=['feature5.1','feature5.2','feature5.3','feature5.4','feature5.5','feature5.6','feature5.7','feature5.8','feature5.9','feature5.10']\n",
    "\n",
    "#combine feature 5 and other 4 features to get complete feature group 1\n",
    "new_df_1=new_df.T.append(feature5.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JE4q8SX-_xnD",
    "outputId": "8437a519-689e-4eb1-f1e5-1d513bbee37d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#X_test_rf = touches_remove_padding(X_test)\n",
    "group1_feature1_data0 = []  # num_of_frames: value; shape: (N,)\n",
    "group1_feature2_data0 = []  # avg_pressure_on_64_chs_over_all_frames; shape: (N,)\n",
    "group1_feature3_data0 = []  # max_value_in_all,shape:(N,)\n",
    "group1_feature4_data0 = []  # no_signal_frames,shape:(N,)\n",
    "group1_feature5_data0 = []  # variations_around_c; shape: (N, 10)\n",
    "\n",
    "all_data0 = []\n",
    "for i in range(len(X_test_rf)):\n",
    "    group1_feature1_data0.append(num_of_frames(X_test_rf[i]))\n",
    "    group1_feature2_data0.append(avg_pressure_on_64_chs_over_all_frames(X_test_rf[i]))\n",
    "    group1_feature3_data0.append(max_value_in_all(X_test_rf[i]))\n",
    "    group1_feature4_data0.append(no_signal_frames(X_test_rf[i]))\n",
    "    group1_feature5_data0.append(variations_around_c(X_test_rf[i]))\n",
    "\n",
    "    \n",
    "all_data0.append(group1_feature1_data0)\n",
    "all_data0.append(group1_feature2_data0)\n",
    "all_data0.append(group1_feature3_data0)\n",
    "all_data0.append(group1_feature4_data0)\n",
    "\n",
    "#ned_df is the feature group 1 without 5th features \n",
    "new_df0 = pd.DataFrame(all_data0)\n",
    "new_df0=new_df0.T\n",
    "new_df0.columns=[\"num_of_frames\", \"avg_pressure_on_64_chs_over_all_frames\",\"max_value_in_all\",\"no_signal_frames\"]\n",
    "\n",
    "feature5_0=pd.DataFrame(group1_feature5_data0)\n",
    "feature5_0.columns=['feature5.1','feature5.2','feature5.3','feature5.4','feature5.5','feature5.6','feature5.7','feature5.8','feature5.9','feature5.10']\n",
    "\n",
    "#combine feature 5 and other 4 features to get complete feature group 1\n",
    "new_df_1_0=new_df0.T.append(feature5_0.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_XT6QaDOAaV"
   },
   "outputs": [],
   "source": [
    "###Feature extraction-channel based feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vj4YtGuPOLpY"
   },
   "outputs": [],
   "source": [
    "#Average pressure of each channel over all frames\n",
    "#X_train_rf\n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "def all_channel(touches):\n",
    "    all_gestures =[]\n",
    "    for index,touch in enumerate(touches):\n",
    "        all_channel = []\n",
    "        for i in range(64):\n",
    "            data_each_channel = [x[i] for x in touch]\n",
    "            all_channel.append(sum(data_each_channel)/len(data_each_channel))\n",
    "        all_gestures.append(all_channel)\n",
    "    output_df = DataFrame(all_gestures)\n",
    "    return output_df\n",
    "all_channel=all_channel(X_train_rf).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yVL6Rp6_3Ab"
   },
   "outputs": [],
   "source": [
    "#X_test_rf\n",
    "def all_channel_0(touches):\n",
    "    all_gestures_0 =[]\n",
    "    for index,touch in enumerate(touches):\n",
    "        all_channel_0 = []\n",
    "        for i in range(64):\n",
    "            data_each_channel = [x[i] for x in touch]\n",
    "            all_channel_0.append(sum(data_each_channel)/len(data_each_channel))\n",
    "        all_gestures_0.append(all_channel_0)\n",
    "    output_df = DataFrame(all_gestures_0)\n",
    "    return output_df\n",
    "all_channel_0=all_channel_0(X_test_rf).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIHLU1h4Oyg3",
    "outputId": "c698cea8-93e9-4702-b143-f7a069012409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress : 99.97864616698698 %"
     ]
    }
   ],
   "source": [
    "#X_train_rf\n",
    "#Percentage of time when a channel has pressure more than a fixed threshold T: \n",
    "#    number of time reach T/number of frames (set T as 90-percentile of all the value in the gesture.)\n",
    "import sys\n",
    "import time\n",
    "\n",
    "def percentage_over_T(touches):\n",
    "    # find a T as threshold\n",
    "    percentage_over_T_df = []\n",
    "    for index,touch in enumerate(touches):\n",
    "        all_data = []\n",
    "        for i in range(64):\n",
    "            channel_data = [x[i] for x in touch]\n",
    "            all_data += channel_data\n",
    "        T = sorted(all_data)[int(0.9*len(all_data))]\n",
    "\n",
    "            # find the percentage when pressure more than T\n",
    "        more_than_T_list = []\n",
    "        for i in range(64):\n",
    "            more_than_T = 0\n",
    "            channel_data = [x[i] for x in touch]\n",
    "            for value in channel_data:\n",
    "                if value > T:\n",
    "                    more_than_T +=1\n",
    "            more_than_T_list.append(more_than_T/len(channel_data))\n",
    "        percentage_over_T_df.append(more_than_T_list)\n",
    "        print(\"\\r\",end=\"\")\n",
    "        print(\"progress : {} %\".format(100*index/len(touches)),end=\"\")\n",
    "        sys.stdout.flush()\n",
    "#         time.sleep(0.05)\n",
    "    \n",
    "    output_df = DataFrame(percentage_over_T_df)\n",
    "    return output_df\n",
    "percentage_over_T=percentage_over_T(X_train_rf).T\n",
    "\n",
    "new_df_2=all_channel.append(percentage_over_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfVakq0uAAKH",
    "outputId": "c548bc71-2c58-4f49-9e98-e0f1ac6b155c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress : 99.93593850096092 %"
     ]
    }
   ],
   "source": [
    "#X_test_rf\n",
    "def percentage_over_T_0(touches):\n",
    "    # find a T as threshold\n",
    "    percentage_over_T_df0 = []\n",
    "    for index,touch in enumerate(touches):\n",
    "        all_data = []\n",
    "        for i in range(64):\n",
    "            channel_data = [x[i] for x in touch]\n",
    "            all_data += channel_data\n",
    "        T = sorted(all_data)[int(0.9*len(all_data))]\n",
    "\n",
    "            # find the percentage when pressure more than T\n",
    "        more_than_T_list = []\n",
    "        for i in range(64):\n",
    "            more_than_T = 0\n",
    "            channel_data = [x[i] for x in touch]\n",
    "            for value in channel_data:\n",
    "                if value > T:\n",
    "                    more_than_T +=1\n",
    "            more_than_T_list.append(more_than_T/len(channel_data))\n",
    "        percentage_over_T_df0.append(more_than_T_list)\n",
    "        print(\"\\r\",end=\"\")\n",
    "        print(\"progress : {} %\".format(100*index/len(touches)),end=\"\")\n",
    "        sys.stdout.flush()\n",
    "#         time.sleep(0.05)\n",
    "    \n",
    "    output_df0 = DataFrame(percentage_over_T_df0)\n",
    "    return output_df0\n",
    "percentage_over_T_0=percentage_over_T_0(X_test_rf).T\n",
    "\n",
    "new_df_2_0=all_channel_0.append(percentage_over_T_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZGBCY0iO4ls"
   },
   "outputs": [],
   "source": [
    "###combine feature group 1 & 2\n",
    "X_train_rf=new_df_1.append(new_df_2).T\n",
    "X_test_rf=new_df_1_0.append(new_df_2_0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ku5oujdAEpk"
   },
   "outputs": [],
   "source": [
    "X_train_rf= np.nan_to_num(X_train_rf.astype(np.float32))\n",
    "X_test_rf= np.nan_to_num(X_test_rf.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUat-NrRUJaf"
   },
   "outputs": [],
   "source": [
    "###Create RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQJ5yeCtQqnY",
    "outputId": "a82e6bf5-0e65-43bf-ac53-29158ed4009e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57847533632287 0.5816784112748238\n"
     ]
    }
   ],
   "source": [
    "rf0 =RandomForestClassifier(oob_score=True,random_state=10)   \n",
    "rf0 = rf0.fit(X_train_rf, y_train)                                         \n",
    "result0 = rf0.score(X_test_rf, y_test) \n",
    "\n",
    "rf1= RandomForestClassifier(n_estimators=140,max_features=9,max_depth=19, min_samples_split=7,min_samples_leaf=1,oob_score=True,random_state=10)  \n",
    "rf1.fit(X_train_rf, y_train) \n",
    "result1 = rf1.score(X_test_rf, y_test) \n",
    "\n",
    "print(result0,result1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMYJRWFZlQk1"
   },
   "source": [
    "### Predict Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASPm2qD7lQGA"
   },
   "outputs": [],
   "source": [
    "y_pred_rf = rf0.predict_proba(X_test_rf) \n",
    " # shape: (N, 14), N == number of len(y_test), 14: probabilty of each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyu4hll9l31u"
   },
   "source": [
    "## 2D CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLGvLTCul-QZ"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObuqxxyXl5jv"
   },
   "outputs": [],
   "source": [
    "X_test_2dcnn,y_test_2dcnn,y_test_id_2dcnn = padding_sample_2dcnn(X_test,y_test)\n",
    "X_train_2dcnn,y_train_2dcnn,y_train_id_2dcnn = padding_sample_2dcnn(X_train,y_train)\n",
    "X_valid_2dcnn,y_valid_2dcnn,y_valid_id_2dcnn = padding_sample_2dcnn(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJr9M_GqmMVS"
   },
   "source": [
    "### Other Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QyYM_Y990Gqb",
    "outputId": "b9d0e041-4769-4a23-bad4-47a034fa582e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11296, 100, 8, 8])\n",
      "torch.Size([3850, 100, 8, 8])\n",
      "torch.Size([3952, 100, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "train_x_2dcnn = torch.from_numpy(X_train_2dcnn).float()\n",
    "train_y_2dcnn = torch.from_numpy(y_train_2dcnn).long()\n",
    "valid_x_2dcnn = torch.from_numpy(X_valid_2dcnn).float()\n",
    "valid_y_2dcnn = torch.from_numpy(y_valid_2dcnn).long()\n",
    "test_x_2dcnn = torch.from_numpy(X_test_2dcnn).float()\n",
    "test_y_2dcnn = torch.from_numpy(y_test_2dcnn).long()\n",
    "print(train_x_2dcnn.shape)\n",
    "print(valid_x_2dcnn.shape)\n",
    "print(test_x_2dcnn.shape)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train_2dcnn = torch.utils.data.TensorDataset(train_x_2dcnn,train_y_2dcnn)\n",
    "valid_2dcnn = torch.utils.data.TensorDataset(valid_x_2dcnn,valid_y_2dcnn)\n",
    "test_2dcnn = torch.utils.data.TensorDataset(test_x_2dcnn,test_y_2dcnn)\n",
    "\n",
    "# data loader\n",
    "train_loader_2dcnn = torch.utils.data.DataLoader(train_2dcnn, batch_size = batch_size, shuffle = False,drop_last=True)\n",
    "valid_loader_2dcnn = torch.utils.data.DataLoader(valid_2dcnn, batch_size = batch_size, shuffle = False,drop_last=True)\n",
    "test_loader_2dcnn = torch.utils.data.DataLoader(test_2dcnn, batch_size = batch_size, shuffle = False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlQqYJsU04I8",
    "outputId": "0f801a18-7df5-419b-a266-89c7bb86dc7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339\n",
      "Network(\n",
      "  (conv1): Conv2d(100, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=224, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=14, bias=True)\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      ")\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(100, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=224, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=14, bias=True)\n",
       "  (dropout): Dropout(p=0.15, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=100, out_channels=64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=56, kernel_size=3)\n",
    "        # self.conv3 = nn.Conv2d(in_channels=56, out_channels=56, kernel_size=3)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=56*2*2, out_features=32)\n",
    "        self.fc2 = nn.Linear(in_features=32, out_features=14)\n",
    "        # self.out = nn.Linear(in_features=16, out_features=14)\n",
    "\n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=F.relu(x)\n",
    "        x=self.conv2(x)\n",
    "        x=F.relu(x)\n",
    "        # x=self.conv3(x)\n",
    "        # x=F.relu(x)\n",
    "        x=F.max_pool2d(x,2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.out(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "n_iters = 30000\n",
    "num_epochs = n_iters / (len(X_train_2dcnn) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)\n",
    "from torch.nn import init\n",
    "\n",
    "# Initilize parameter\n",
    "def weights_init(m):\n",
    "    classname=m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.xavier_uniform(m.weight.data)\n",
    "        # torch.nn.init.xavier_uniform(m.bias.data)\n",
    "\n",
    "# Create CNN\n",
    "model_2dcnn = Network()\n",
    "#model.cuda()\n",
    "print(model_2dcnn)\n",
    "model_2dcnn.apply(weights_init)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model_2dcnn.parameters(), lr=learning_rate)\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model_2dcnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugqQrhJe06ra",
    "outputId": "9708dc0b-be28-4edf-fd5c-177d56d870de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 64, 6, 6]          57,664\n",
      "            Conv2d-2             [-1, 56, 4, 4]          32,312\n",
      "            Linear-3                   [-1, 32]           7,200\n",
      "           Dropout-4                   [-1, 32]               0\n",
      "            Linear-5                   [-1, 14]             462\n",
      "================================================================\n",
      "Total params: 97,638\n",
      "Trainable params: 97,638\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.03\n",
      "Params size (MB): 0.37\n",
      "Estimated Total Size (MB): 0.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_2dcnn, (100,8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOjPUE3U080s"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVU5Z9qj0_GL"
   },
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, patience, n_epochs):\n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = [] \n",
    "    \n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train() # prep model for training\n",
    "        for batch, (data, target) in enumerate(train_loader_2dcnn, 1):\n",
    "            # send data to GPU\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # record training loss\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        \n",
    "        model.eval() # prep model for evaluation\n",
    "        for data, target in valid_loader_2dcnn:\n",
    "            # send data to GPU\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # record validation loss\n",
    "            valid_losses.append(loss.item())\n",
    "\n",
    "        # print training/validation statistics \n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        \n",
    "        epoch_len = len(str(n_epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "        \n",
    "        print(print_msg)\n",
    "        \n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        \n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return  model, avg_train_losses, avg_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekSWudq91BQs",
    "outputId": "7011bb5d-286e-45be-fdf3-5289ab5fcaef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(100, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=224, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=14, bias=True)\n",
       "  (dropout): Dropout(p=0.15, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# patience = 10\n",
    "\n",
    "# model, train_loss, valid_loss = train_model(model, batch_size, patience, num_epochs)\n",
    "\n",
    "model_2dcnn.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/2dcnn.pth\"))\n",
    "model_2dcnn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5FtcIGsmNt4"
   },
   "source": [
    "### Predict Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbbxA5L9mMse",
    "outputId": "79d530e9-bc42-45c5-8ad5-eb20ca4bde1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# subsample accuracy test\n",
    "# =======================================================\n",
    "from collections import Counter\n",
    "test_loss = 0.0\n",
    "num_classes = 14\n",
    " \n",
    "model_2dcnn.eval() # prep model for evaluation\n",
    "batch_no = 0\n",
    "prediction_weight_list = []\n",
    "counter_test_id_batch = Counter(y_test_id_2dcnn)\n",
    "output_sub = 0\n",
    "# test_id_list = list(set(y_test_id.tolist()))\n",
    "current_id = y_test_id_2dcnn[0]\n",
    "batch_size_evaluation= 128\n",
    "for data, target in test_loader_2dcnn:\n",
    "    if len(target.data) != batch_size:\n",
    "        print('here')\n",
    "        batch_size_evaluation = len(target.data)\n",
    "    # send data to GPU\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model_2dcnn(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # print(output)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "        \n",
    "    \n",
    "    for i in range(batch_size_evaluation):\n",
    "        \n",
    "        if y_test_id_2dcnn[i+batch_no*batch_size]==current_id:\n",
    "          output_sub += output[i]\n",
    "        \n",
    "          \n",
    "        else:\n",
    "          prediction_weight = (output_sub/counter_test_id_batch[current_id]).cpu().detach().numpy().tolist()\n",
    "          prediction_weight_list.append(prediction_weight)\n",
    "          current_id = y_test_id_2dcnn[i+batch_no*batch_size]\n",
    "          output_sub = output[i]\n",
    " \n",
    "    batch_no +=1\n",
    "prediction_weight = (output_sub/counter_test_id_batch[current_id]).cpu().detach().numpy().tolist()\n",
    "prediction_weight_list.append(prediction_weight)\n",
    "y_pred_2dcnn = torch.Tensor(prediction_weight_list) \n",
    "# print_test_accuracy(np.argmax(y_pred_2dcnn,axis =1),np.array(y_test),num_classes) \n",
    "# y_pred_3dcnn  # shape: (N, 14), N == number of len(y_test), 14: probabilty of each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7F9XE6VCmSgI"
   },
   "source": [
    "## 3D CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TOVe60ZmVJx"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdLb1PDomUQz"
   },
   "outputs": [],
   "source": [
    "X_test_3dcnn,y_test_3dcnn,y_test_id_3dcnn = padding_sample_3dcnn(X_test,y_test) \n",
    "X_train_3dcnn,y_train_3dcnn,y_train_id_3dcnn = padding_sample_3dcnn(X_train,y_train)    \n",
    "X_valid_3dcnn,y_valid_3dcnn,y_valid_id_3dcnn = padding_sample_3dcnn(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weZFG130msBS"
   },
   "source": [
    "### Other Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tT46PnX-Ygq7",
    "outputId": "260206b9-894b-4701-cd65-798c6f1d8b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11296, 1, 100, 8, 8])\n",
      "torch.Size([3850, 1, 100, 8, 8])\n",
      "torch.Size([3952, 1, 100, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "train_x_3dcnn = torch.from_numpy(X_train_3dcnn).float()\n",
    "train_y_3dcnn = torch.from_numpy(y_train_3dcnn).long()\n",
    "valid_x_3dcnn = torch.from_numpy(X_valid_3dcnn).float()\n",
    "valid_y_3dcnn = torch.from_numpy(y_valid_3dcnn).long()\n",
    "test_x_3dcnn = torch.from_numpy(X_test_3dcnn).float()\n",
    "test_y_3dcnn = torch.from_numpy(y_test_3dcnn).long()\n",
    "print(train_x_3dcnn.shape)\n",
    "print(valid_x_3dcnn.shape)\n",
    "print(test_x_3dcnn.shape)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train_3dcnn = torch.utils.data.TensorDataset(train_x_3dcnn,train_y_3dcnn)\n",
    "valid_3dcnn = torch.utils.data.TensorDataset(valid_x_3dcnn,valid_y_3dcnn)\n",
    "test_3dcnn = torch.utils.data.TensorDataset(test_x_3dcnn,test_y_3dcnn)\n",
    "\n",
    "# data loader\n",
    "train_loader_3dcnn = torch.utils.data.DataLoader(train_3dcnn, batch_size = batch_size, shuffle = False,drop_last=True)\n",
    "valid_loader_3dcnn = torch.utils.data.DataLoader(valid_3dcnn, batch_size = batch_size, shuffle = False,drop_last=True)\n",
    "test_loader_3dcnn = torch.utils.data.DataLoader(test_3dcnn, batch_size = batch_size, shuffle = False,drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCDYpLBTZdn8"
   },
   "source": [
    "3D CNN net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbeIU4yXZhRa",
    "outputId": "868afe61-69d2-497d-aebc-9df056b493a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339\n",
      "C3D(\n",
      "  (conv1): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (pool1): MaxPool3d(kernel_size=(3, 1, 1), stride=(3, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (pool2): MaxPool3d(kernel_size=(3, 2, 2), stride=(3, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (pool3): MaxPool3d(kernel_size=(3, 1, 1), stride=(3, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc6): Linear(in_features=5632, out_features=1024, bias=True)\n",
      "  (fc7): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (fc8): Linear(in_features=128, out_features=14, bias=True)\n",
      "  (soft): Softmax(dim=1)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (batch): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:74: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "C3D(\n",
       "  (conv1): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool1): MaxPool3d(kernel_size=(3, 1, 1), stride=(3, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool2): MaxPool3d(kernel_size=(3, 2, 2), stride=(3, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool3): MaxPool3d(kernel_size=(3, 1, 1), stride=(3, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc6): Linear(in_features=5632, out_features=1024, bias=True)\n",
       "  (fc7): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc8): Linear(in_features=128, out_features=14, bias=True)\n",
       "  (soft): Softmax(dim=1)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (batch): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from mypath import Path\n",
    "class C3D(nn.Module):\n",
    "    \"\"\"\n",
    "    The C3D network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, pretrained=False):\n",
    "        super(C3D, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=(3, 3, 3),padding=1)   # 1,16,85,8,8\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(3, 1, 1))      # 1,16,350,8,8\n",
    "\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=(3, 3, 3),padding=1)  # 1,32,350,8,8\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(3, 2, 2))      # 1,32,70,4,4\n",
    "\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=(3, 3, 3),padding=1)   # 1,64,70,8,8\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(3, 1, 1))      # 1,64,23,8,8\n",
    "\n",
    "        # self.conv4 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3),padding=1)  # 1，128，23，6，6\n",
    "        # self.pool4 = nn.MaxPool3d(kernel_size=(3, 1,1))      # 1，128，4，2，2\n",
    "\n",
    "# The number of fully connected layers is 3. The number of units in the fully connected layers is 1024\n",
    "\n",
    "        self.fc6 = nn.Linear(32*11*4*4, 1024)\n",
    "        self.fc7 = nn.Linear(1024, 128)\n",
    "        self.fc8 = nn.Linear(128, num_classes)\n",
    "        self.soft = nn.Softmax( dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.batch=nn.BatchNorm1d(128)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # self.__init_weight()\n",
    "\n",
    "        # if pretrained:\n",
    "        #     self.__load_pretrained_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        # x = self.relu(self.conv3(x))\n",
    "        # x = self.pool3(x)\n",
    "\n",
    "        print(x.shape)\n",
    "        # x = x.view(-1, 524288)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.batch(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        logits = self.fc8(x)\n",
    "        output = self.soft(logits)\n",
    "#         print(output)\n",
    "        return output\n",
    "\n",
    "n_iters = 30000\n",
    "num_epochs = n_iters / (len(train_x_3dcnn) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)\n",
    "from torch.nn import init\n",
    "\n",
    "# Initilize parameter\n",
    "def weights_init(m):\n",
    "    classname=m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.xavier_uniform(m.weight.data)\n",
    "        # torch.nn.init.xavier_uniform(m.bias.data)\n",
    "\n",
    "# Create CNN\n",
    "model_3dcnn = C3D(14)\n",
    "#model_3dcnn.cuda()\n",
    "print(model_3dcnn)\n",
    "model_3dcnn.apply(weights_init)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model_3dcnn.parameters(), lr=learning_rate)\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model_3dcnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ht2GUhUGZw8b"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HnOsG4IZziD"
   },
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, patience, n_epochs):\n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = [] \n",
    "    \n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train() # prep model for training\n",
    "        for batch, (data, target) in enumerate(train_loader_3dcnn, 1):\n",
    "            # send data to GPU\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # record training loss\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        \n",
    "        model.eval() # prep model for evaluation\n",
    "        for data, target in valid_loader_3dcnn:\n",
    "            # send data to GPU\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # record validation loss\n",
    "            valid_losses.append(loss.item())\n",
    "\n",
    "        # print training/validation statistics \n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        \n",
    "        epoch_len = len(str(n_epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "        \n",
    "        print(print_msg)\n",
    "        \n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        \n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return  model, avg_train_losses, avg_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wn3Xpx24pdDi",
    "outputId": "d1e9285d-f6a4-41f5-d2b8-0050e0c9deea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C3D(\n",
       "  (conv1): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool1): MaxPool3d(kernel_size=(3, 1, 1), stride=(3, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool2): MaxPool3d(kernel_size=(3, 2, 2), stride=(3, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool3): MaxPool3d(kernel_size=(3, 1, 1), stride=(3, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc6): Linear(in_features=5632, out_features=1024, bias=True)\n",
       "  (fc7): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc8): Linear(in_features=128, out_features=14, bias=True)\n",
       "  (soft): Softmax(dim=1)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (batch): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# patience = 10\n",
    " \n",
    "# model_3dcnn, train_loss, valid_loss = train_model(model_3dcnn, batch_size, patience, num_epochs)\n",
    "\n",
    "model_3dcnn.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/3dcnn.pth\"))\n",
    "model_3dcnn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Dobafkqmu-s"
   },
   "source": [
    "### Predict Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hX3Gd_UmsXp",
    "outputId": "f29e4f96-6acc-4152-9701-98d3ea05a45d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "torch.Size([128, 32, 11, 4, 4])\n",
      "here\n",
      "torch.Size([112, 32, 11, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[8.8621e-04, 9.8607e-04, 3.6517e-04,  ..., 1.8187e-03, 1.7678e-03,\n",
       "         3.1985e-02],\n",
       "        [1.2617e-03, 2.4812e-03, 2.5000e-03,  ..., 2.2073e-02, 3.5973e-03,\n",
       "         6.2896e-01],\n",
       "        [7.0918e-05, 9.9881e-01, 5.4137e-07,  ..., 8.1263e-06, 1.7068e-04,\n",
       "         9.3588e-07],\n",
       "        ...,\n",
       "        [2.8668e-03, 3.5448e-04, 1.3922e-02,  ..., 2.0583e-03, 7.7945e-04,\n",
       "         1.2281e-04],\n",
       "        [5.2617e-05, 9.9872e-01, 9.4594e-07,  ..., 1.8800e-05, 1.1878e-04,\n",
       "         9.2127e-07],\n",
       "        [2.2983e-02, 4.2175e-02, 3.8039e-01,  ..., 8.4318e-02, 2.9362e-02,\n",
       "         4.3146e-02]])"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =======================================================\n",
    "# subsample accuracy test\n",
    "# =======================================================\n",
    "from collections import Counter\n",
    "test_loss = 0.0\n",
    "num_classes = 14\n",
    "\n",
    "model_3dcnn.eval() # prep model for evaluation\n",
    "batch_no = 0\n",
    "prediction_weight_list = []\n",
    "counter_test_id_batch = Counter(y_test_id_3dcnn)\n",
    "output_sub = 0\n",
    "# test_id_list = list(set(y_test_id_3dcnn.tolist()))\n",
    "current_id = y_test_id_3dcnn[0]\n",
    "batch_size_evaluation= 128\n",
    "for data, target in test_loader_3dcnn:\n",
    "    if len(target.data) != batch_size:\n",
    "        print('here')\n",
    "        batch_size_evaluation = len(target.data)\n",
    "    # send data to GPU\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model_3dcnn(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # print(output)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "        \n",
    "    \n",
    "    for i in range(batch_size_evaluation):\n",
    "        \n",
    "        if y_test_id_3dcnn[i+batch_no*batch_size]==current_id:\n",
    "          output_sub += output[i]\n",
    "        \n",
    "          \n",
    "        else:\n",
    "          prediction_weight = (output_sub/counter_test_id_batch[current_id]).cpu().detach().numpy().tolist()\n",
    "          prediction_weight_list.append(prediction_weight)\n",
    "          current_id = y_test_id_3dcnn[i+batch_no*batch_size]\n",
    "          output_sub = output[i]\n",
    "\n",
    "    batch_no +=1\n",
    "prediction_weight = (output_sub/counter_test_id_batch[current_id]).cpu().detach().numpy().tolist()\n",
    "prediction_weight_list.append(prediction_weight)\n",
    "y_pred_3dcnn = torch.Tensor(prediction_weight_list) \n",
    "\n",
    "y_pred_3dcnn  # shape: (N, 14), N == number of len(y_test), 14: probabilty of each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82BDzzAGmyg0"
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9nGWWCLpMUV"
   },
   "outputs": [],
   "source": [
    "def print_test_accuracy(y_pred, y_test, num_classes):\n",
    "    class_correct = list(0. for i in range(num_classes))\n",
    "    class_total = list(0. for i in range(num_classes))\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        label = y_test[i]\n",
    "        class_correct[label] += int(y_pred[i] == y_test[i])\n",
    "        class_total[label] += 1\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        if class_total[i] > 0:\n",
    "            print('Test Accuracy of %5s: %2.2f%% (%2d/%2d)' % (\n",
    "                str(i), 100 * class_correct[i] / class_total[i],\n",
    "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "    print('\\nTest Accuracy (Overall): %2.2f%% (%2d/%2d)' % (\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAx0BtuwnXMe"
   },
   "source": [
    "### Solution 1 (Simple Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hrIX_FlnPys",
    "outputId": "d4e0fa59-2c52-4a06-e21a-c14350baf9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of     0: 78.57% (88/112)\n",
      "Test Accuracy of     1: 58.04% (65/112)\n",
      "Test Accuracy of     2: 81.98% (91/111)\n",
      "Test Accuracy of     3: 41.44% (46/111)\n",
      "Test Accuracy of     4: 71.43% (80/112)\n",
      "Test Accuracy of     5: 64.29% (72/112)\n",
      "Test Accuracy of     6: 60.71% (68/112)\n",
      "Test Accuracy of     7: 43.24% (48/111)\n",
      "Test Accuracy of     8: 45.05% (50/111)\n",
      "Test Accuracy of     9: 52.68% (59/112)\n",
      "Test Accuracy of    10: 26.13% (29/111)\n",
      "Test Accuracy of    11: 61.26% (68/111)\n",
      "Test Accuracy of    12: 24.11% (27/112)\n",
      "Test Accuracy of    13: 79.28% (88/111)\n",
      "\n",
      "Test Accuracy (Overall): 56.31% (879/1561)\n"
     ]
    }
   ],
   "source": [
    "y_pred_s1 = y_pred_rf + y_pred_2dcnn.numpy() + y_pred_3dcnn.numpy()\n",
    "y_pred_s1 = np.argmax(y_pred_s1, axis=1)\n",
    "\n",
    "print_test_accuracy(y_pred_s1, y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGC3O6enp0dq"
   },
   "source": [
    "### Solution 2 (Weighted Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nspy82FXYxsc",
    "outputId": "09d5b297-b26a-461b-e98d-5eadb0c4598b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of     0: 79.46% (89/112)\n",
      "Test Accuracy of     1: 59.82% (67/112)\n",
      "Test Accuracy of     2: 81.08% (90/111)\n",
      "Test Accuracy of     3: 50.45% (56/111)\n",
      "Test Accuracy of     4: 77.68% (87/112)\n",
      "Test Accuracy of     5: 76.79% (86/112)\n",
      "Test Accuracy of     6: 66.96% (75/112)\n",
      "Test Accuracy of     7: 44.14% (49/111)\n",
      "Test Accuracy of     8: 50.45% (56/111)\n",
      "Test Accuracy of     9: 72.32% (81/112)\n",
      "Test Accuracy of    10: 32.43% (36/111)\n",
      "Test Accuracy of    11: 68.47% (76/111)\n",
      "Test Accuracy of    12: 26.79% (30/112)\n",
      "Test Accuracy of    13: 84.68% (94/111)\n",
      "\n",
      "Test Accuracy (Overall): 62.27% (972/1561)\n"
     ]
    }
   ],
   "source": [
    "weights = [0.38, 0.12, 0.5]\n",
    "\n",
    "y_pred_s2 = y_pred_rf * weights[0] + y_pred_2dcnn.numpy() * weights[1] + y_pred_3dcnn.numpy() * weights[2]\n",
    "y_pred_s2 = np.argmax(y_pred_s2, axis=1)\n",
    "\n",
    "print_test_accuracy(y_pred_s2, y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jS900aGEHTA"
   },
   "source": [
    "### Independent Models Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bw91p8PPD2Ny",
    "outputId": "e2d24f07-f4bf-4aed-9c21-248e54ddf2e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of     0: 73.21% (82/112)\n",
      "Test Accuracy of     1: 52.68% (59/112)\n",
      "Test Accuracy of     2: 75.68% (84/111)\n",
      "Test Accuracy of     3: 45.95% (51/111)\n",
      "Test Accuracy of     4: 67.86% (76/112)\n",
      "Test Accuracy of     5: 75.00% (84/112)\n",
      "Test Accuracy of     6: 67.86% (76/112)\n",
      "Test Accuracy of     7: 41.44% (46/111)\n",
      "Test Accuracy of     8: 39.64% (44/111)\n",
      "Test Accuracy of     9: 62.50% (70/112)\n",
      "Test Accuracy of    10: 38.74% (43/111)\n",
      "Test Accuracy of    11: 68.47% (76/111)\n",
      "Test Accuracy of    12: 45.54% (51/112)\n",
      "Test Accuracy of    13: 54.95% (61/111)\n",
      "\n",
      "Test Accuracy (Overall): 57.85% (903/1561)\n"
     ]
    }
   ],
   "source": [
    "## Random Forest ##\n",
    "\n",
    "print_test_accuracy(np.argmax(y_pred_rf, axis=1), np.array(y_test), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RlbVjWhuEUXk",
    "outputId": "d65d2b9e-6971-48ca-f419-7e85b23a267a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of     0: 78.57% (88/112)\n",
      "Test Accuracy of     1: 46.43% (52/112)\n",
      "Test Accuracy of     2: 81.08% (90/111)\n",
      "Test Accuracy of     3: 28.83% (32/111)\n",
      "Test Accuracy of     4: 61.61% (69/112)\n",
      "Test Accuracy of     5: 58.04% (65/112)\n",
      "Test Accuracy of     6: 47.32% (53/112)\n",
      "Test Accuracy of     7: 36.04% (40/111)\n",
      "Test Accuracy of     8: 14.41% (16/111)\n",
      "Test Accuracy of     9: 25.00% (28/112)\n",
      "Test Accuracy of    10: 15.32% (17/111)\n",
      "Test Accuracy of    11: 35.14% (39/111)\n",
      "Test Accuracy of    12: 12.50% (14/112)\n",
      "Test Accuracy of    13: 53.15% (59/111)\n",
      "\n",
      "Test Accuracy (Overall): 42.41% (662/1561)\n"
     ]
    }
   ],
   "source": [
    "## 2D CNN ##\n",
    "\n",
    "print_test_accuracy(np.argmax(y_pred_2dcnn, axis=1), np.array(y_test), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOM53i2TEWIR",
    "outputId": "fb50a867-f9ee-46f4-e523-d92a1751877b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of     0: 76.79% (86/112)\n",
      "Test Accuracy of     1: 55.36% (62/112)\n",
      "Test Accuracy of     2: 79.28% (88/111)\n",
      "Test Accuracy of     3: 54.05% (60/111)\n",
      "Test Accuracy of     4: 79.46% (89/112)\n",
      "Test Accuracy of     5: 68.75% (77/112)\n",
      "Test Accuracy of     6: 66.07% (74/112)\n",
      "Test Accuracy of     7: 42.34% (47/111)\n",
      "Test Accuracy of     8: 51.35% (57/111)\n",
      "Test Accuracy of     9: 75.89% (85/112)\n",
      "Test Accuracy of    10: 33.33% (37/111)\n",
      "Test Accuracy of    11: 63.06% (70/111)\n",
      "Test Accuracy of    12: 17.86% (20/112)\n",
      "Test Accuracy of    13: 85.59% (95/111)\n",
      "\n",
      "Test Accuracy (Overall): 60.67% (947/1561)\n"
     ]
    }
   ],
   "source": [
    "## 3D CNN ##\n",
    "\n",
    "print_test_accuracy(np.argmax(y_pred_3dcnn, axis=1), np.array(y_test), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "If1BzPyPEXfq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ZGeEi1oPj9Dm"
   ],
   "name": "Ensemble.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
